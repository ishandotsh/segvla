{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import logging\n",
        "import time\n",
        "from contextlib import nullcontext\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "from torch.amp import GradScaler\n",
        "from torch.optim import Optimizer\n",
        "\n",
        "from lerobot.configs.default import DatasetConfig, EvalConfig, WandBConfig\n",
        "from lerobot.configs.train import TrainPipelineConfig\n",
        "from lerobot.envs.configs import LiberoEnv\n",
        "from lerobot.policies.segvla.configuration_segvla import SegVLAConfig\n",
        "from lerobot.utils.logging_utils import AverageMeter, MetricsTracker\n",
        "from lerobot.utils.random_utils import set_seed\n",
        "from lerobot.utils.utils import get_safe_torch_device, has_method, init_logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def update_policy(\n",
        "    train_metrics: MetricsTracker,\n",
        "    policy,\n",
        "    batch,\n",
        "    optimizer: Optimizer,\n",
        "    grad_clip_norm: float,\n",
        "    grad_scaler: GradScaler,\n",
        "    lr_scheduler=None,\n",
        "    use_amp: bool = False,\n",
        "    lock=None,\n",
        "):\n",
        "    start_time = time.perf_counter()\n",
        "    device = next(policy.parameters()).device\n",
        "    policy.train()\n",
        "    autocast_context = torch.autocast(device_type=device.type) if use_amp else nullcontext()\n",
        "    with autocast_context:\n",
        "        loss, output_dict = policy.forward(batch)\n",
        "    grad_scaler.scale(loss).backward()\n",
        "    grad_scaler.unscale_(optimizer)\n",
        "    grad_norm = torch.nn.utils.clip_grad_norm_(\n",
        "        policy.parameters(),\n",
        "        grad_clip_norm,\n",
        "        error_if_nonfinite=False,\n",
        "    )\n",
        "    with lock if lock is not None else nullcontext():\n",
        "        grad_scaler.step(optimizer)\n",
        "    grad_scaler.update()\n",
        "    optimizer.zero_grad()\n",
        "    if lr_scheduler is not None:\n",
        "        lr_scheduler.step()\n",
        "    if has_method(policy, \"update\"):\n",
        "        policy.update()\n",
        "    train_metrics.loss = loss.item()\n",
        "    train_metrics.grad_norm = grad_norm.item()\n",
        "    train_metrics.lr = optimizer.param_groups[0][\"lr\"]\n",
        "    train_metrics.update_s = time.perf_counter() - start_time\n",
        "    return train_metrics, output_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:lerobot.configs.policies:Device 'None' is not available. Switching to 'cuda'.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Policy: segvla\n",
            "Dataset repo: HuggingFaceVLA/libero\n",
            "Env task: libero_10\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "OUTPUT_DIR = Path('outputs/segvla_libero')\n",
        "if os.path.exists(OUTPUT_DIR):\n",
        "    shutil.rmtree(OUTPUT_DIR)\n",
        "\n",
        "dataset_cfg = DatasetConfig(\n",
        "    repo_id='HuggingFaceVLA/libero',\n",
        "    root=None,\n",
        "    streaming=False,\n",
        "    use_imagenet_stats=True,\n",
        ")\n",
        "\n",
        "policy_cfg = SegVLAConfig(\n",
        "    push_to_hub=False,\n",
        "    pretrained_path=None,\n",
        "    load_vlm_weights=False,\n",
        "    use_amp=False,\n",
        ")\n",
        "\n",
        "env_cfg = LiberoEnv(\n",
        "    task='libero_10',\n",
        "    init_states=True,\n",
        "    camera_name='agentview_image,robot0_eye_in_hand_image',\n",
        ")\n",
        "\n",
        "eval_cfg = EvalConfig(n_episodes=1, batch_size=1, use_async_envs=False)\n",
        "\n",
        "cfg = TrainPipelineConfig(\n",
        "    dataset=dataset_cfg,\n",
        "    policy=policy_cfg,\n",
        "    env=env_cfg,\n",
        "    batch_size=2,\n",
        "    steps=20,\n",
        "    num_workers=2,\n",
        "    eval=eval_cfg,\n",
        "    eval_freq=0,\n",
        "    log_freq=5,\n",
        "    save_checkpoint=False,\n",
        "    wandb=WandBConfig(enable=False),\n",
        "    output_dir=OUTPUT_DIR,\n",
        ")\n",
        "\n",
        "cfg.validate()\n",
        "print('Policy:', cfg.policy.type)\n",
        "print('Dataset repo:', cfg.dataset.repo_id)\n",
        "print('Env task:', cfg.env.task)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "init_logging()\n",
        "if cfg.seed is not None:\n",
        "    set_seed(cfg.seed)\n",
        "device = get_safe_torch_device(cfg.policy.device, log=True)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "print('Using device:', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total episodes: 1693\n",
            "Total frames: 273465\n",
            "Batch keys: dict_keys(['observation.images.image', 'observation.images.image2', 'observation.state', 'action', 'timestamp', 'frame_index', 'episode_index', 'index', 'task_index', 'observation.images.image_is_pad', 'observation.images.image2_is_pad', 'observation.state_is_pad', 'action_is_pad', 'task'])\n"
          ]
        }
      ],
      "source": [
        "from lerobot.datasets.factory import make_dataset\n",
        "from lerobot.datasets.sampler import EpisodeAwareSampler\n",
        "from lerobot.datasets.utils import cycle\n",
        "\n",
        "dataset = make_dataset(cfg)\n",
        "print(f'Total episodes: {dataset.num_episodes}')\n",
        "print(f'Total frames: {dataset.num_frames}')\n",
        "\n",
        "if hasattr(cfg.policy, 'drop_n_last_frames'):\n",
        "    sampler = EpisodeAwareSampler(\n",
        "        dataset.meta.episodes['dataset_from_index'],\n",
        "        dataset.meta.episodes['dataset_to_index'],\n",
        "        drop_n_last_frames=cfg.policy.drop_n_last_frames,\n",
        "        shuffle=True,\n",
        "    )\n",
        "    shuffle = False\n",
        "else:\n",
        "    sampler = None\n",
        "    shuffle = True\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    num_workers=cfg.num_workers,\n",
        "    batch_size=cfg.batch_size,\n",
        "    shuffle=shuffle and not cfg.dataset.streaming,\n",
        "    sampler=sampler,\n",
        "    pin_memory=device.type == 'cuda',\n",
        "    drop_last=False,\n",
        "    prefetch_factor=2,\n",
        ")\n",
        "dl_iter = cycle(dataloader)\n",
        "first_batch = next(dl_iter)\n",
        "print('Batch keys:', first_batch.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating LIBERO envs | suites=['libero_10'] | n_envs(per task)=1 | init_states=True\n",
            "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "Built vec env | suite=libero_10 | task_id=0 | n_envs=1\n",
            "Built vec env | suite=libero_10 | task_id=1 | n_envs=1\n",
            "Built vec env | suite=libero_10 | task_id=2 | n_envs=1\n",
            "Built vec env | suite=libero_10 | task_id=3 | n_envs=1\n",
            "Built vec env | suite=libero_10 | task_id=4 | n_envs=1\n",
            "Built vec env | suite=libero_10 | task_id=5 | n_envs=1\n",
            "Built vec env | suite=libero_10 | task_id=6 | n_envs=1\n",
            "Built vec env | suite=libero_10 | task_id=7 | n_envs=1\n",
            "Built vec env | suite=libero_10 | task_id=8 | n_envs=1\n",
            "Built vec env | suite=libero_10 | task_id=9 | n_envs=1\n",
            "Eval suites: ['libero_10']\n"
          ]
        }
      ],
      "source": [
        "from lerobot.envs.factory import make_env\n",
        "from lerobot.envs.utils import close_envs\n",
        "\n",
        "if cfg.env is not None:\n",
        "    eval_env = make_env(cfg.env, n_envs=cfg.eval.batch_size, use_async_envs=cfg.eval.use_async_envs)\n",
        "    print('Eval suites:', list(eval_env.keys()))\n",
        "else:\n",
        "    eval_env = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reducing the number of VLM layers to 16 ...\n",
            "Policy parameters: 450046176\n"
          ]
        }
      ],
      "source": [
        "from lerobot.policies.factory import make_policy, make_pre_post_processors\n",
        "\n",
        "policy = make_policy(cfg.policy, ds_meta=dataset.meta)\n",
        "processor_kwargs = {}\n",
        "if (cfg.policy.pretrained_path and not cfg.resume) or not cfg.policy.pretrained_path:\n",
        "    processor_kwargs['dataset_stats'] = dataset.meta.stats\n",
        "preprocessor, postprocessor = make_pre_post_processors(\n",
        "    policy_cfg=cfg.policy,\n",
        "    pretrained_path=cfg.policy.pretrained_path,\n",
        "    **processor_kwargs,\n",
        ")\n",
        "print('Policy parameters:', sum(p.numel() for p in policy.parameters()) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO 2025-11-21 10:24:09 hedulers.py:105 Auto-scaling LR scheduler: num_training_steps (20) < num_decay_steps (30000). Scaling warmup: 1000 → 0, decay: 30000 → 20 (scale factor: 0.001)\n"
          ]
        }
      ],
      "source": [
        "from lerobot.optim.factory import make_optimizer_and_scheduler\n",
        "\n",
        "optimizer, lr_scheduler = make_optimizer_and_scheduler(cfg, policy)\n",
        "grad_scaler = GradScaler(device.type, enabled=cfg.policy.use_amp)\n",
        "\n",
        "train_meters = {\n",
        "    'loss': AverageMeter('loss', ':.3f'),\n",
        "    'grad_norm': AverageMeter('grdn', ':.3f'),\n",
        "    'lr': AverageMeter('lr', ':0.1e'),\n",
        "    'update_s': AverageMeter('updt_s', ':.3f'),\n",
        "    'dataloading_s': AverageMeter('data_s', ':.3f'),\n",
        "}\n",
        "train_tracker = MetricsTracker(\n",
        "    cfg.batch_size, dataset.num_frames, dataset.num_episodes, train_meters, initial_step=0\n",
        ")\n",
        "step = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "733b80d1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "seg_logits is none\n",
            "seg_logits is none\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'key' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m batch \u001b[38;5;241m=\u001b[39m preprocessor(batch)\n\u001b[1;32m      7\u001b[0m train_tracker\u001b[38;5;241m.\u001b[39mdataloading_s \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m----> 8\u001b[0m train_tracker, output_dict \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_policy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_tracker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad_clip_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scaler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scaler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_amp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_amp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     19\u001b[0m train_tracker\u001b[38;5;241m.\u001b[39mstep()\n",
            "Cell \u001b[0;32mIn[2], line 17\u001b[0m, in \u001b[0;36mupdate_policy\u001b[0;34m(train_metrics, policy, batch, optimizer, grad_clip_norm, grad_scaler, lr_scheduler, use_amp, lock)\u001b[0m\n\u001b[1;32m     15\u001b[0m autocast_context \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautocast(device_type\u001b[38;5;241m=\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype) \u001b[38;5;28;01mif\u001b[39;00m use_amp \u001b[38;5;28;01melse\u001b[39;00m nullcontext()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_context:\n\u001b[0;32m---> 17\u001b[0m     loss, output_dict \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m grad_scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     19\u001b[0m grad_scaler\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n",
            "File \u001b[0;32m~/sjsu/dl/proj/lerobot/src/lerobot/policies/segvla/modeling_segvla.py:329\u001b[0m, in \u001b[0;36mSegVLAPolicy.forward\u001b[0;34m(self, batch, noise, time)\u001b[0m\n\u001b[1;32m    327\u001b[0m actions_is_pad \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactions_id_pad\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    328\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 329\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseg_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m loss_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlosses_after_forward\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m losses\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m actions_is_pad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/sjsu/dl/proj/lerobot/src/lerobot/policies/segvla/modeling_segvla.py:1038\u001b[0m, in \u001b[0;36mVLAFlowMatching.forward\u001b[0;34m(self, images, img_masks, seg_logits, lang_tokens, lang_masks, state, actions, noise, time)\u001b[0m\n\u001b[1;32m   1036\u001b[0m x_t \u001b[38;5;241m=\u001b[39m time_expanded \u001b[38;5;241m*\u001b[39m noise \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m time_expanded) \u001b[38;5;241m*\u001b[39m actions\n\u001b[1;32m   1037\u001b[0m u_t \u001b[38;5;241m=\u001b[39m noise \u001b[38;5;241m-\u001b[39m actions\n\u001b[0;32m-> 1038\u001b[0m prefix_embs, prefix_pad_masks, prefix_att_masks, seg_metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_prefix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseg_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1041\u001b[0m suffix_embs, suffix_pad_masks, suffix_att_masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_suffix(\n\u001b[1;32m   1042\u001b[0m     x_t, time, seg_metadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1043\u001b[0m )\n\u001b[1;32m   1045\u001b[0m pad_masks \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([prefix_pad_masks, suffix_pad_masks], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[0;32m~/sjsu/dl/proj/lerobot/src/lerobot/policies/segvla/modeling_segvla.py:812\u001b[0m, in \u001b[0;36mVLAFlowMatching.embed_prefix\u001b[0;34m(self, images, img_masks, seg_logits, lang_tokens, lang_masks, state)\u001b[0m\n\u001b[1;32m    809\u001b[0m img_mask \u001b[38;5;241m=\u001b[39m img_mask[:, \u001b[38;5;28;01mNone\u001b[39;00m]\u001b[38;5;241m.\u001b[39mexpand(bsize, num_img_embs)\n\u001b[1;32m    811\u001b[0m embs\u001b[38;5;241m.\u001b[39mappend(img_emb)\n\u001b[0;32m--> 812\u001b[0m emb_names\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mkey\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_img\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    813\u001b[0m pad_masks\u001b[38;5;241m.\u001b[39mappend(img_mask)\n\u001b[1;32m    815\u001b[0m att_masks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m (num_img_embs)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'key' is not defined"
          ]
        }
      ],
      "source": [
        "MAX_VIS_STEPS = min(cfg.steps, 5)\n",
        "policy.train()\n",
        "for _ in range(MAX_VIS_STEPS):\n",
        "    start_time = time.perf_counter()\n",
        "    batch = next(dl_iter)\n",
        "    batch = preprocessor(batch)\n",
        "    train_tracker.dataloading_s = time.perf_counter() - start_time\n",
        "    train_tracker, output_dict = update_policy(\n",
        "        train_tracker,\n",
        "        policy,\n",
        "        batch,\n",
        "        optimizer,\n",
        "        cfg.optimizer.grad_clip_norm,\n",
        "        grad_scaler=grad_scaler,\n",
        "        lr_scheduler=lr_scheduler,\n",
        "        use_amp=cfg.policy.use_amp,\n",
        "    )\n",
        "    step += 1\n",
        "    train_tracker.step()\n",
        "    if step % cfg.log_freq == 0 or step == MAX_VIS_STEPS:\n",
        "        print(train_tracker)\n",
        "        train_tracker.reset_averages()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lerobot.scripts.lerobot_eval import eval_policy_all\n",
        "\n",
        "if eval_env is not None:\n",
        "    with torch.no_grad(), torch.autocast(device_type=device.type, enabled=cfg.policy.use_amp):\n",
        "        eval_info = eval_policy_all(\n",
        "            envs=eval_env,\n",
        "            policy=policy,\n",
        "            preprocessor=preprocessor,\n",
        "            postprocessor=postprocessor,\n",
        "            n_episodes=cfg.eval.n_episodes,\n",
        "            videos_dir=cfg.output_dir / 'eval_videos',\n",
        "            max_episodes_rendered=1,\n",
        "            start_seed=cfg.seed,\n",
        "            max_parallel_tasks=cfg.env.max_parallel_tasks,\n",
        "        )\n",
        "    print('Eval overall metrics:', eval_info['overall'])\n",
        "    close_envs(eval_env)\n",
        "else:\n",
        "    print('Eval env not created.')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "lerobot",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
